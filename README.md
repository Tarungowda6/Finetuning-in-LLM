# Finetuning-in-LLM
PEFT Fine-tuning large language model (LLM)

PEFT Fine-tuning large language model (LLM)
By: Tarun S Gowda
Introduction:
A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize
and generate text, among other tasks. LLMs are trained on huge sets of data— hence the name
"large." LLMs are built on machine learning specifically, a type of neural networking called a
transformer model.
In simpler terms, an LLM is a computer program that has been fed enough examples to be able to
recognize and interpret human language or other types of complex data. Many LLMs are trained
on data that has been gathered from the Internet — thousands or millions of gigabytes' worth of
text. But the quality of the samples impacts how well LLMs will learn natural language, so an
LLM's programmers may use a more curated data set.
LLMs use a type of machine learning called deep learning in order to understand how characters,
words, and sentences function together. Deep learning involves the probabilistic analysis of
unstructured data, which eventually enables the deep learning model to recognize distinctions
between pieces of content without human intervention.
LLMs are then further trained via tuning: they are fine-tuned or prompt-tuned to the particular task
that the programmer wants them to do, such as interpreting questions and generating responses, or
translating text from one language to another.
Large Language Models (LLMs) have dramatically transformed natural language processing
(NLP), excelling in tasks like text generation, translation, summarization, and question-answering.
However, these models may not always be ideal for specific domains or tasks.
To address this, fine-tuning is performed. Fine-tuning customizes pre-trained LLMs to better suit
specialized applications by refining the model on smaller, task-specific
datasets. This allows the model to enhance its performance while retaining its broad language proficiency


